{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ce2200-fea2-4569-82cd-af86c06974a9",
   "metadata": {},
   "source": [
    "# Run the code block below before either model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f701b980-52d2-4298-be85-b1b6bc593ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, Dropout,\n",
    "                                     GlobalAveragePooling2D, BatchNormalization)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "# Enable memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Load data\n",
    "data_train = np.load('data_train.npy')\n",
    "labels_train = np.load('labels_train.npy')\n",
    "\n",
    "# Split the data\n",
    "train_df, test_df, train_df_labels, test_df_labels = train_test_split(data_train.T, labels_train, test_size=0.2, random_state=42)\n",
    "X_train = train_df.reshape(-1, 300, 300, 3)\n",
    "X_test = test_df.reshape(-1, 300, 300, 3)\n",
    "\n",
    "# Label encoding\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(train_df_labels)\n",
    "y_test = lb.transform(test_df_labels)  # Use transform here, not fit_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a5589d-6cc3-4690-8d79-a6175a472f07",
   "metadata": {},
   "source": [
    "# Code block for better model that crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f32df6-57dd-42bf-9d58-ae92332fcbc1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 14:54:57.376228: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 14:54:58.725513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78911 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:07:00.0, compute capability: 8.0\n",
      "2023-11-29 14:54:58.727318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78911 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:bd:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 14:55:04.984113: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2023-11-29 14:55:07.150224: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845/845 [==============================] - 95s 104ms/step - loss: 1.0619 - accuracy: 0.6866 - val_loss: 0.4903 - val_accuracy: 0.8863\n"
     ]
    }
   ],
   "source": [
    "# 89% accuracy but crashes\n",
    "\n",
    "# Data augmentation\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=30,  # Allow rotation for augmenting rotated images\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,  # Shear might simulate different hand angles\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load pre-trained ResNet50 model as a base\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "\n",
    "# Unfreeze the entire base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Add regularization with L2\n",
    "regularizer = l2(1e-5)\n",
    "\n",
    "# Add new layers on top of the base model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, activation='relu', kernel_regularizer=regularizer),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(9, activation='softmax', kernel_regularizer=regularizer)  # 9 classes for ASL A-I\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5)\n",
    "checkpoint = ModelCheckpoint('best_model_resnet.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train the model with data augmentation\n",
    "batch_size = 8 \n",
    "\n",
    "history = model.fit(\n",
    "    data_gen.flow(X_train, y_train, batch_size=batch_size), \n",
    "    epochs=50, \n",
    "    validation_data=(X_test, y_test), \n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint]\n",
    ")\n",
    "\n",
    "# Load the best model\n",
    "best_model = tf.keras.models.load_model('best_model_resnet.h5')\n",
    "\n",
    "# Evaluate on the validation set\n",
    "val_loss, val_accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511dcb52-3923-4a8a-9bff-1461e606c93a",
   "metadata": {},
   "source": [
    "# GOAT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d640c4fc-a204-4c89-aab2-e18051760b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 15:21:59.543037: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 15:22:00.918291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78911 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:07:00.0, compute capability: 8.0\n",
      "2023-11-29 15:22:00.920066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78911 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:bd:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 15:22:07.845676: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2023-11-29 15:22:09.788612: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 28s 102ms/step - loss: 0.7003 - accuracy: 0.7994 - val_loss: 0.1948 - val_accuracy: 0.9449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.1438 - accuracy: 0.9615 - val_loss: 0.2033 - val_accuracy: 0.9390\n",
      "Epoch 3/50\n",
      "212/212 [==============================] - 19s 89ms/step - loss: 0.1076 - accuracy: 0.9702 - val_loss: 0.1106 - val_accuracy: 0.9739\n",
      "Epoch 4/50\n",
      "212/212 [==============================] - 19s 89ms/step - loss: 0.0831 - accuracy: 0.9784 - val_loss: 0.1208 - val_accuracy: 0.9686\n",
      "Epoch 5/50\n",
      "212/212 [==============================] - 19s 89ms/step - loss: 0.0988 - accuracy: 0.9753 - val_loss: 0.1108 - val_accuracy: 0.9680\n",
      "Epoch 6/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.0402 - accuracy: 0.9927 - val_loss: 0.1534 - val_accuracy: 0.9739\n",
      "Epoch 7/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.0383 - accuracy: 0.9929 - val_loss: 0.1256 - val_accuracy: 0.9674\n",
      "Epoch 8/50\n",
      "212/212 [==============================] - 19s 89ms/step - loss: 0.0351 - accuracy: 0.9947 - val_loss: 0.1022 - val_accuracy: 0.9828\n",
      "Epoch 9/50\n",
      "212/212 [==============================] - 19s 89ms/step - loss: 0.0551 - accuracy: 0.9879 - val_loss: 0.1656 - val_accuracy: 0.9609\n",
      "Epoch 10/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.0481 - accuracy: 0.9889 - val_loss: 0.1200 - val_accuracy: 0.9716\n",
      "Epoch 11/50\n",
      "212/212 [==============================] - 19s 89ms/step - loss: 0.0657 - accuracy: 0.9849 - val_loss: 0.1994 - val_accuracy: 0.9586\n",
      "Epoch 12/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.0388 - accuracy: 0.9929 - val_loss: 0.1638 - val_accuracy: 0.9686\n",
      "Epoch 13/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.0321 - accuracy: 0.9948 - val_loss: 0.1491 - val_accuracy: 0.9668\n",
      "Epoch 14/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.0267 - accuracy: 0.9966 - val_loss: 0.0893 - val_accuracy: 0.9811\n",
      "Epoch 15/50\n",
      "212/212 [==============================] - 19s 89ms/step - loss: 0.0180 - accuracy: 0.9993 - val_loss: 0.0859 - val_accuracy: 0.9828\n",
      "Epoch 16/50\n",
      "212/212 [==============================] - 19s 89ms/step - loss: 0.0152 - accuracy: 0.9999 - val_loss: 0.0875 - val_accuracy: 0.9822\n",
      "Epoch 17/50\n",
      "212/212 [==============================] - 19s 89ms/step - loss: 0.0157 - accuracy: 0.9993 - val_loss: 0.0872 - val_accuracy: 0.9805\n",
      "Epoch 18/50\n",
      "212/212 [==============================] - 19s 89ms/step - loss: 0.0157 - accuracy: 0.9997 - val_loss: 0.0896 - val_accuracy: 0.9816\n",
      "Epoch 19/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.0155 - accuracy: 0.9996 - val_loss: 0.0836 - val_accuracy: 0.9828\n",
      "Epoch 20/50\n",
      "212/212 [==============================] - 19s 89ms/step - loss: 0.0157 - accuracy: 0.9994 - val_loss: 0.0847 - val_accuracy: 0.9828\n",
      "Epoch 21/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.0149 - accuracy: 0.9999 - val_loss: 0.0837 - val_accuracy: 0.9846\n",
      "Epoch 22/50\n",
      "212/212 [==============================] - 19s 89ms/step - loss: 0.0159 - accuracy: 0.9997 - val_loss: 0.0823 - val_accuracy: 0.9852\n",
      "Epoch 23/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.0178 - accuracy: 0.9985 - val_loss: 0.0882 - val_accuracy: 0.9840\n",
      "Epoch 24/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.0149 - accuracy: 0.9999 - val_loss: 0.0882 - val_accuracy: 0.9852\n",
      "Epoch 25/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.0153 - accuracy: 0.9996 - val_loss: 0.0914 - val_accuracy: 0.9834\n",
      "Epoch 26/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.0166 - accuracy: 0.9991 - val_loss: 0.0971 - val_accuracy: 0.9816\n",
      "Epoch 27/50\n",
      "212/212 [==============================] - 20s 95ms/step - loss: 0.0176 - accuracy: 0.9991 - val_loss: 0.0947 - val_accuracy: 0.9840\n",
      "Epoch 28/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.0176 - accuracy: 0.9987 - val_loss: 0.0943 - val_accuracy: 0.9846\n",
      "Epoch 29/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.0147 - accuracy: 0.9997 - val_loss: 0.0941 - val_accuracy: 0.9852\n",
      "Epoch 30/50\n",
      "212/212 [==============================] - 19s 90ms/step - loss: 0.0153 - accuracy: 0.9999 - val_loss: 0.0954 - val_accuracy: 0.9858\n",
      "Epoch 31/50\n",
      "212/212 [==============================] - 19s 89ms/step - loss: 0.0149 - accuracy: 0.9999 - val_loss: 0.0944 - val_accuracy: 0.9846\n",
      "Epoch 32/50\n",
      "212/212 [==============================] - 19s 89ms/step - loss: 0.0146 - accuracy: 0.9997 - val_loss: 0.0924 - val_accuracy: 0.9846\n",
      "53/53 [==============================] - 2s 25ms/step - loss: 0.0823 - accuracy: 0.9852\n",
      "Validation Loss: 0.08225207030773163, Validation Accuracy: 0.9851983189582825\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "base_model.trainable = True\n",
    "\n",
    "regularizer = l2(1e-5)\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, activation='relu', kernel_regularizer=regularizer),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(9, activation='softmax', kernel_regularizer=regularizer)  # 9 classes for ASL A-I\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5)\n",
    "checkpoint = ModelCheckpoint('best_model_resnet.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[early_stopping, reduce_lr, checkpoint])\n",
    "\n",
    "best_model = tf.keras.models.load_model('best_model_resnet.h5')\n",
    "\n",
    "# Evaluate on the validation set\n",
    "val_loss, val_accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ecf94-c3e7-4360-8264-d2644d55e8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
